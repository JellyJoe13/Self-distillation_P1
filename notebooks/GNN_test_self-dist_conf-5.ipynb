{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91c75dc-13da-4ba7-b3cf-073321d8f976",
   "metadata": {},
   "source": [
    "# Graph Neural Network test student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee66cc-4aa3-44f9-af9a-a0e1388f8b3c",
   "metadata": {},
   "source": [
    "-5th specification:\n",
    " - same model as teacher\n",
    " - take most secure self distillation elements as additional input, no matter which label\n",
    " - smooth label input: take the predicted value and not 1. or 0.\n",
    " - significatly higher level of noise (dropout ratio): 0.5\n",
    " - longer length of training (as dropout may lead to slower learning), 300 epochs\n",
    " - shuffled after combining training and sd-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efebdbc-54da-445d-a2b8-a5aac2122c3a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:04.345702Z",
     "end_time": "2023-06-10T17:46:04.354703Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0b741-4708-4953-ac45-010196c26c2b",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119dbbbe-8f0f-463f-a2dd-d3f331e03c0d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:09.762776Z",
     "end_time": "2023-06-10T17:46:43.408433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\anaconda3\\envs\\praktikum\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from selfdist_toolkit.pyg_tools import gnn_load, GIN_nn, execution, sd_utils, accuracy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f32cd-6b16-4351-ac12-7e7e673fd390",
   "metadata": {},
   "source": [
    "## Data loading (aid list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e1714a-ca4b-4a4b-90b8-df569df3aef0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.409433Z",
     "end_time": "2023-06-10T17:46:43.423433Z"
    }
   },
   "outputs": [],
   "source": [
    "aid_list = pd.read_csv(\"../results/random_forest/experiments_check/chem-desc_good-aid_1.csv\").aid.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f231e521-6a55-45dc-82ef-b062928bd0e3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.424432Z",
     "end_time": "2023-06-10T17:46:43.449433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([    884,     891,     899,     914,    1418,    1431,    1770,\n          1771,    1795,  493073,  493102,  493177,  493191,  493240,\n        588834,  651741,  651812,  651814,  686978,  687022,  720691,\n        743036,  743040,  743065, 1053173, 1259381, 1346982])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ea429-9c6f-4935-9cbd-9c8b6bc1e404",
   "metadata": {},
   "source": [
    "## Procedure environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7dc139-83f1-41bb-ac9b-00597757b1c5",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.441433Z",
     "end_time": "2023-06-10T17:46:43.466433Z"
    }
   },
   "outputs": [],
   "source": [
    "# fraction of self distillation elements to add to training\n",
    "frac_sd = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63066a98-c85c-4178-850c-6802a834c613",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.457434Z",
     "end_time": "2023-06-10T17:46:43.489433Z"
    }
   },
   "outputs": [],
   "source": [
    "# number epochs\n",
    "epochs = 300\n",
    "original_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae7e952-ba4f-453e-acb2-c392f2295e6d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.473433Z",
     "end_time": "2023-06-10T17:46:43.490433Z"
    }
   },
   "outputs": [],
   "source": [
    "# random state where we want to set it\n",
    "random_state = 131313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7953f8-6b8e-410d-873f-a30f7716c0d2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.488433Z",
     "end_time": "2023-06-10T17:46:43.504433Z"
    }
   },
   "outputs": [],
   "source": [
    "# hard mode - soft mode is actually deprecated\n",
    "mode = \"hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db6a175e-fc23-40b5-8b3f-959d6d3c36ce",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.505433Z",
     "end_time": "2023-06-10T17:46:43.525433Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch size\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9e22b-661f-4fe8-90b4-52376409b1c6",
   "metadata": {},
   "source": [
    "## Setting up storage location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918f907d-e93d-44ea-b725-54b948b67861",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.521433Z",
     "end_time": "2023-06-10T17:46:43.537433Z"
    }
   },
   "outputs": [],
   "source": [
    "# path for csv dataframe\n",
    "csv_path = \"../results/student_exp_-5/csv/\"\n",
    "# path for graphs\n",
    "graphs_path = \"../results/student_exp_-5/graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8a7f45-6014-4d8d-9367-f246c8264404",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.537433Z",
     "end_time": "2023-06-10T17:46:43.557433Z"
    }
   },
   "outputs": [],
   "source": [
    "# make sure the folder exists\n",
    "if not os.path.exists(csv_path):\n",
    "    os.makedirs(csv_path)\n",
    "if not os.path.exists(graphs_path):\n",
    "    os.makedirs(graphs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829ebde-5a8e-4c1b-b6a6-4a5b237192a0",
   "metadata": {},
   "source": [
    "## Determine which self distillation entries to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190cb69c-a161-4ca1-9d09-3305e9cab4cf",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:46:43.554433Z",
     "end_time": "2023-06-10T17:46:43.568433Z"
    }
   },
   "outputs": [],
   "source": [
    "def pick_sd_basic(\n",
    "    num_current: int,\n",
    "    perc_select: float,\n",
    "    aid: int\n",
    ") -> typing.List[torch_geometric.data.data.Data]:\n",
    "    \n",
    "    # =================================================\n",
    "    # Load self distillation elements for this aid\n",
    "    # =================================================\n",
    "    # define path where the self distillation prediction is\n",
    "    path_sd_data = \"../results/teacher_exp/sd_out/teacher-pred_aid={}_epochs={}.csv\".format(aid, original_epochs)\n",
    "\n",
    "    # read the self distillation data\n",
    "    df_sd = pd.read_csv(path_sd_data)\n",
    "\n",
    "    # sort the elements according to their difference to 0.5 to get most secure predictions\n",
    "    idx_sorted = np.argsort(np.abs(df_sd.predicted_label_soft.to_numpy()-0.5))[::-1]\n",
    "\n",
    "    # determine number of self distillation elements to fetch\n",
    "    num_sd = int(perc_select*num_current)\n",
    "\n",
    "    # get subset of df to take\n",
    "    df_sd = df_sd.loc[idx_sorted][:num_sd]\n",
    "\n",
    "    # calculate the pyg elements of the chosen elements\n",
    "    sd_data_list = gnn_load.load_pyg_data_from_smiles_list(df_sd.smiles.tolist(), df_sd.predicted_label_soft.tolist())\n",
    "\n",
    "    return sd_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b996003e-c508-4519-889d-a6a0206bad5f",
   "metadata": {},
   "source": [
    "## Iteration over assay ids and execution of procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6589870-617a-472b-b820-0f24dd886211",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-06-10T17:47:35.589896Z",
     "end_time": "2023-06-10T17:47:35.611293Z"
    }
   },
   "outputs": [],
   "source": [
    "forbidden_aid=[686978]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b042f2-6998-43dc-aa53-140117930c80",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 884, 0/27 - 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [27:13<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 891, 1/27 - 3.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [22:35<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 899, 2/27 - 7.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [23:50<00:00,  4.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 914, 3/27 - 11.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [22:09<00:00,  4.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 1418, 4/27 - 14.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:48<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 1431, 5/27 - 18.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:15<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 1770, 6/27 - 22.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:19<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 1771, 7/27 - 25.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:40<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 1795, 8/27 - 29.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:55<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 493073, 9/27 - 33.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:54<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 493102, 10/27 - 37.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:55<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 493177, 11/27 - 40.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:08<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 493191, 12/27 - 44.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:27<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 493240, 13/27 - 48.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:11<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 588834, 14/27 - 51.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [08:42<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 651741, 15/27 - 55.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:13<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 651812, 16/27 - 59.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:46<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 651814, 17/27 - 62.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:20<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 686978, 18/27 - 66.67%\n",
      "skipped because in forbidden list\n",
      "current aid: 687022, 19/27 - 70.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:18<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 720691, 20/27 - 74.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [15:29<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 743036, 21/27 - 77.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [14:55<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 743040, 22/27 - 81.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [16:50<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 743065, 23/27 - 85.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 246/300 [12:57<02:46,  3.08s/it]"
     ]
    }
   ],
   "source": [
    "for i, aid in enumerate(aid_list):\n",
    "    \n",
    "    # =================================================\n",
    "    # Progress output\n",
    "    # =================================================\n",
    "    # print actual state\n",
    "    print(\"current aid: {}, {}/{} - {:2.2%}\".format(\n",
    "        aid,\n",
    "        i,\n",
    "        aid_list.shape[0],\n",
    "        i/aid_list.shape[0]\n",
    "    ))\n",
    "    \n",
    "    # if experiment in forbidden experiments skip it\n",
    "    if aid in forbidden_aid:\n",
    "        print(\"skipped because in forbidden list\")\n",
    "        continue\n",
    "    \n",
    "    # =================================================\n",
    "    # Load data\n",
    "    # =================================================\n",
    "    # load data for experiment\n",
    "    whole_data = gnn_load.load_pyg_data_aid(aid=aid, label_type=mode, do_in_parallel=True, path_data=\"../data/\")\n",
    "    # seperate because this should only be in training data\n",
    "    sd_data = pick_sd_basic(len(whole_data), frac_sd, aid)\n",
    "    \n",
    "    # get hard labels\n",
    "    labels_hard = np.array([\n",
    "        data.y.detach().cpu().numpy()\n",
    "        for data in whole_data\n",
    "    ]).flatten().astype(int)\n",
    "    \n",
    "    # do data splitting in train and test 80:20\n",
    "    # data splitting\n",
    "    for train_idx, test_idx in StratifiedShuffleSplit(n_splits=1, random_state=random_state, test_size=0.2).split(whole_data, labels_hard):\n",
    "        break\n",
    "    \n",
    "    # fuze data and shuffle it to make internal distribution more equal\n",
    "    fuzed_data = [whole_data[idx] for idx in train_idx] + sd_data\n",
    "    random.Random(random_state).shuffle(fuzed_data)\n",
    "    \n",
    "    \n",
    "    # generate the dataloader\n",
    "    dl_train = torch_geometric.loader.DataLoader(fuzed_data, batch_size=(batch_size if aid!=686978 else batch_size*10))\n",
    "    dl_test = torch_geometric.loader.DataLoader([whole_data[idx] for idx in test_idx], batch_size=(batch_size if aid!=686978 else batch_size*10))\n",
    "    \n",
    "    # =================================================\n",
    "    # Model setup\n",
    "    # =================================================\n",
    "    # GNN model\n",
    "    model = GIN_nn.GIN_basic(1)\n",
    "    # loss\n",
    "    loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([(len(train_idx) + len(sd_data))/(labels_hard[train_idx].sum() + torch.concatenate([data.y for data in sd_data]).numpy().sum())]))\n",
    "    # device\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device)\n",
    "    loss = loss.to(device)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # =================================================\n",
    "    # Epoch iteration\n",
    "    # =================================================\n",
    "    # define loss saving space\n",
    "    loss_storage = []\n",
    "    \n",
    "    # define accuracy storage\n",
    "    accuracy_storage = []\n",
    "    \n",
    "    # epoch iterations\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        # do training step\n",
    "        loss_value = execution.training(model, dl_train, device, optimizer, loss, verbose=False)\n",
    "\n",
    "        # put loss into storage\n",
    "        loss_storage.append(loss_value)\n",
    "\n",
    "        # do testing step\n",
    "        y_pred_hard = execution.predict(model, dl_test, device, reduce_to_hard_label=True, verbose=False)\n",
    "\n",
    "        # calculate accuracy DataFrame\n",
    "        accuracy_storage.append(\n",
    "            # get accuracy class and from it the DataFrame\n",
    "            accuracy.calculate_accuracies_1d(\n",
    "                y_pred=y_pred_hard, \n",
    "                y_true=accuracy.helper_pyg_to_numpy_label(\n",
    "                    data_loader=dl_test\n",
    "                )\n",
    "            ).to_df(index=epoch)\n",
    "        )\n",
    "    \n",
    "    # transform accuracy storage to pandas df\n",
    "    accuracy_storage = pd.concat(accuracy_storage)\n",
    "\n",
    "    # add new column for loss\n",
    "    accuracy_storage['loss'] = loss_storage\n",
    "    \n",
    "    # =================================================\n",
    "    # Save data to file\n",
    "    # =================================================\n",
    "    # set file path\n",
    "    file_path = csv_path + \"student-acc_aid={}_epochs={}.csv\".format(aid, epochs)\n",
    "    \n",
    "    # write to file\n",
    "    accuracy_storage.to_csv(file_path, index=True, index_label=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a395b-f73f-4af0-971a-065d1d9e4356",
   "metadata": {},
   "source": [
    "## Generate the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35cc91-e52c-4e5b-a820-74af605f1184",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for aid in aid_list:\n",
    "    \n",
    "    # if experiment in forbidden experiments skip it\n",
    "    if aid in forbidden_aid:\n",
    "        continue\n",
    "    \n",
    "    # determine storage location of csv\n",
    "    file_path = csv_path + \"student-acc_aid={}_epochs={}.csv\".format(aid, epochs)\n",
    "    \n",
    "    # determine storage location of image\n",
    "    file_path_plot = graphs_path + \"StudentAccs_aid-{}_epochs-{}.png\".format(aid, epochs)\n",
    "    \n",
    "    # load the csv\n",
    "    loaded_csv = pd.read_csv(file_path, index_col=\"epoch\")\n",
    "    \n",
    "    # plotting\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(loaded_csv.roc_score, label=\"roc_score\")\n",
    "    ax1.plot(loaded_csv.precision, label=\"precision\")\n",
    "    ax1.plot(loaded_csv.recall, label=\"recall\")\n",
    "    ax2.plot(loaded_csv.loss, color=\"black\", label=\"loss\")\n",
    "    \n",
    "    ax1.set_xlabel(\"epoch\")\n",
    "    ax1.set_ylabel(\"accuracy score\")\n",
    "    ax2.set_ylabel(\"loss score\")\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    plt.title(\"Accuracy scores on student model test - aid={}\".format(aid))\n",
    "    plt.savefig(file_path_plot, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08424452-e204-4660-bf67-03f662dd0dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
