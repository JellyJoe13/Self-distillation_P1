{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91c75dc-13da-4ba7-b3cf-073321d8f976",
   "metadata": {},
   "source": [
    "# Graph Neural Network test student - teacher reduced to 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee66cc-4aa3-44f9-af9a-a0e1388f8b3c",
   "metadata": {},
   "source": [
    "specification:\n",
    " - same model as teacher\n",
    " - take most secure self distillation elements as additional input but keep positive - negative ratio\n",
    " - smooth label input: take the predicted value and not 1. or 0.\n",
    " - dropout ratio: 0.5 (both student and teacher)\n",
    " - 150 epochs\n",
    " - shuffled after combining training and sd-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efebdbc-54da-445d-a2b8-a5aac2122c3a",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:07.280019Z",
     "end_time": "2023-05-20T18:54:07.288244Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0b741-4708-4953-ac45-010196c26c2b",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119dbbbe-8f0f-463f-a2dd-d3f331e03c0d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:07.289243Z",
     "end_time": "2023-05-20T18:54:08.935691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\anaconda3\\envs\\praktikum\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from selfdist_toolkit.pyg_tools import gnn_load, GIN_nn, execution, sd_utils, accuracy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f32cd-6b16-4351-ac12-7e7e673fd390",
   "metadata": {},
   "source": [
    "## Data loading (aid list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e1714a-ca4b-4a4b-90b8-df569df3aef0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:08.937691Z",
     "end_time": "2023-05-20T18:54:08.951000Z"
    }
   },
   "outputs": [],
   "source": [
    "aid_list = pd.read_csv(\"../results/random_forest/experiments_check/chem-desc_good-aid_1.csv\").aid.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f231e521-6a55-45dc-82ef-b062928bd0e3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:08.952002Z",
     "end_time": "2023-05-20T18:54:08.981464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([    884,     891,     899,     914,    1418,    1431,    1770,\n          1771,    1795,  493073,  493102,  493177,  493191,  493240,\n        588834,  651741,  651812,  651814,  686978,  687022,  720691,\n        743036,  743040,  743065, 1053173, 1259381, 1346982])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ea429-9c6f-4935-9cbd-9c8b6bc1e404",
   "metadata": {},
   "source": [
    "## Procedure environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7dc139-83f1-41bb-ac9b-00597757b1c5",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:08.966465Z",
     "end_time": "2023-05-20T18:54:08.982464Z"
    }
   },
   "outputs": [],
   "source": [
    "# fraction of self distillation elements to add to training\n",
    "frac_sd = 0.95 * 0.8\n",
    "perc_train = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63066a98-c85c-4178-850c-6802a834c613",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:08.983465Z",
     "end_time": "2023-05-20T18:54:09.003464Z"
    }
   },
   "outputs": [],
   "source": [
    "# number epochs\n",
    "epochs = 150\n",
    "original_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae7e952-ba4f-453e-acb2-c392f2295e6d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:09.000468Z",
     "end_time": "2023-05-20T18:54:09.037629Z"
    }
   },
   "outputs": [],
   "source": [
    "# random state where we want to set it\n",
    "random_state = 131313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7953f8-6b8e-410d-873f-a30f7716c0d2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:09.015465Z",
     "end_time": "2023-05-20T18:54:09.037629Z"
    }
   },
   "outputs": [],
   "source": [
    "# hard mode - soft mode is actually deprecated\n",
    "mode = \"hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db6a175e-fc23-40b5-8b3f-959d6d3c36ce",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:09.030628Z",
     "end_time": "2023-05-20T18:54:09.049630Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch size\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9e22b-661f-4fe8-90b4-52376409b1c6",
   "metadata": {},
   "source": [
    "## Setting up storage location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918f907d-e93d-44ea-b725-54b948b67861",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:09.047629Z",
     "end_time": "2023-05-20T18:54:09.064629Z"
    }
   },
   "outputs": [],
   "source": [
    "# path for csv dataframe\n",
    "csv_path = \"../results/student_rebuilt/csv/\"\n",
    "# path for graphs\n",
    "graphs_path = \"../results/student_rebuilt/graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8a7f45-6014-4d8d-9367-f246c8264404",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:09.062629Z",
     "end_time": "2023-05-20T18:54:09.078629Z"
    }
   },
   "outputs": [],
   "source": [
    "# make sure the folder exists\n",
    "if not os.path.exists(csv_path):\n",
    "    os.makedirs(csv_path)\n",
    "if not os.path.exists(graphs_path):\n",
    "    os.makedirs(graphs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829ebde-5a8e-4c1b-b6a6-4a5b237192a0",
   "metadata": {},
   "source": [
    "## Determine which self distillation entries to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190cb69c-a161-4ca1-9d09-3305e9cab4cf",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:09.079629Z",
     "end_time": "2023-05-20T18:54:09.095629Z"
    }
   },
   "outputs": [],
   "source": [
    "def pick_sd_basic(\n",
    "    num_current: int,\n",
    "    perc_select: float,\n",
    "    aid: int,\n",
    "    pos_to_neg_ratio: float\n",
    ") -> typing.List[torch_geometric.data.data.Data]:\n",
    "    \n",
    "    # =================================================\n",
    "    # Load self distillation elements for this aid\n",
    "    # =================================================\n",
    "    # define path where the self distillation prediction is\n",
    "    path_sd_data = \"../results/teacher_exp_data-reduced2/sd_out/teacher-pred_aid={}_epochs={}.csv\".format(aid, original_epochs)\n",
    "\n",
    "    # read the self distillation data\n",
    "    df_sd = pd.read_csv(path_sd_data)\n",
    "\n",
    "    # sort the elements according to their score\n",
    "    idx_sorted = np.argsort(df_sd.predicted_label_soft.to_numpy())\n",
    "\n",
    "    # determine number of self distillation elements to fetch\n",
    "    num_sd = int(perc_select*num_current)\n",
    "    pos_elem_count = int(num_sd * pos_to_neg_ratio)\n",
    "    neg_elem_count = num_sd - pos_elem_count\n",
    "    \n",
    "    # select most secure positive and negative elements\n",
    "    select = np.concatenate([idx_sorted[:neg_elem_count], idx_sorted[-pos_elem_count:]])\n",
    "\n",
    "    # get subset of df to take\n",
    "    df_sd = df_sd.loc[select]\n",
    "\n",
    "    # calculate the pyg elements of the chosen elements\n",
    "    sd_data_list = gnn_load.load_pyg_data_from_smiles_list(df_sd.smiles.tolist(), df_sd.predicted_label_soft.tolist())\n",
    "\n",
    "    return sd_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b996003e-c508-4519-889d-a6a0206bad5f",
   "metadata": {},
   "source": [
    "## Iteration over assay ids and execution of procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6589870-617a-472b-b820-0f24dd886211",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-20T18:54:09.094629Z",
     "end_time": "2023-05-20T18:54:09.109629Z"
    }
   },
   "outputs": [],
   "source": [
    "forbidden_aid=[686978]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b042f2-6998-43dc-aa53-140117930c80",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-05T22:05:42.229611Z",
     "end_time": "2023-05-05T22:46:16.165227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 651812, 0/27 - 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:05<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current aid: 651814, 1/27 - 3.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 99/150 [00:32<00:16,  3.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 79\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# epoch iterations\u001B[39;00m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(epochs)):\n\u001B[0;32m     77\u001B[0m     \n\u001B[0;32m     78\u001B[0m     \u001B[38;5;66;03m# do training step\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m     loss_value \u001B[38;5;241m=\u001B[39m \u001B[43mexecution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdl_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;66;03m# put loss into storage\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     loss_storage\u001B[38;5;241m.\u001B[39mappend(loss_value)\n",
      "File \u001B[1;32mD:\\DATEN\\Self-distillation_P1\\selfdist_toolkit\\pyg_tools\\execution.py:74\u001B[0m, in \u001B[0;36mtraining\u001B[1;34m(model, trainings_data, device, optimizer, loss_criterion, batch_size, verbose)\u001B[0m\n\u001B[0;32m     71\u001B[0m batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;66;03m# calculate the labels\u001B[39;00m\n\u001B[1;32m---> 74\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m     76\u001B[0m \u001B[38;5;66;03m# use the loss criterion to generate the loss\u001B[39;00m\n\u001B[0;32m     77\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_criterion(y_pred, batch\u001B[38;5;241m.\u001B[39my)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\praktikum\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\DATEN\\Self-distillation_P1\\selfdist_toolkit\\pyg_tools\\GIN_nn.py:192\u001B[0m, in \u001B[0;36mGIN_basic.forward\u001B[1;34m(self, batched_data)\u001B[0m\n\u001B[0;32m    186\u001B[0m     node_representation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformation_lin(tmp)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;66;03m# ==============================================================================================\u001B[39;00m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# result to h_node\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m# global node embedding/feature pooling using the batch mask which tells the algorithm which of the nodes\u001B[39;00m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;66;03m# belong to which graph\u001B[39;00m\n\u001B[1;32m--> 192\u001B[0m h_graph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpooling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_representation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;66;03m# Generate the output which happens by putting the pooled results through another linear layer\u001B[39;00m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgraph_pred_linear(h_graph)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\praktikum\\lib\\site-packages\\torch_geometric\\nn\\pool\\glob.py:62\u001B[0m, in \u001B[0;36mglobal_mean_pool\u001B[1;34m(x, batch, size)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39mdim, keepdim\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 62\u001B[0m size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m size\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scatter(x, batch, dim\u001B[38;5;241m=\u001B[39mdim, dim_size\u001B[38;5;241m=\u001B[39msize, reduce\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i, aid in enumerate(aid_list[16:]):\n",
    "    \n",
    "    # =================================================\n",
    "    # Progress output\n",
    "    # =================================================\n",
    "    # print actual state\n",
    "    print(\"current aid: {}, {}/{} - {:2.2%}\".format(\n",
    "        aid,\n",
    "        i,\n",
    "        aid_list.shape[0],\n",
    "        i/aid_list.shape[0]\n",
    "    ))\n",
    "    \n",
    "    # if experiment in forbidden experiments skip it\n",
    "    if aid in forbidden_aid:\n",
    "        print(\"skipped because in forbidden list\")\n",
    "        continue\n",
    "    \n",
    "    # =================================================\n",
    "    # Load data\n",
    "    # =================================================\n",
    "    # load data for experiment\n",
    "    whole_data = gnn_load.load_pyg_data_aid(aid=aid, label_type=mode, do_in_parallel=True, path_data=\"../data/\")\n",
    "    # seperate because this should only be in training data\n",
    "    pos_neg_ratio = torch.concatenate([data.y for data in whole_data]).numpy().sum()/len(whole_data)\n",
    "    sd_data = pick_sd_basic(len(whole_data), frac_sd, aid, pos_neg_ratio)\n",
    "    \n",
    "    # get hard labels\n",
    "    labels_hard = np.array([\n",
    "        data.y.detach().cpu().numpy()\n",
    "        for data in whole_data\n",
    "    ]).flatten().astype(int)\n",
    "    \n",
    "    # do data splitting in train and test 80:20\n",
    "    # data splitting\n",
    "    for train_idx, test_idx in StratifiedShuffleSplit(n_splits=1, random_state=random_state, test_size=0.2).split(whole_data, labels_hard):\n",
    "        break\n",
    "\n",
    "    # REDUCE TRAINING DATA TO 50%\n",
    "    random.seed(random_state)\n",
    "    train_idx = random.sample(train_idx.tolist(), int(perc_train*len(train_idx)))\n",
    "        \n",
    "    # fuze data and shuffle it to make internal distribution more equal\n",
    "    fuzed_data = [whole_data[idx] for idx in train_idx] + sd_data\n",
    "    random.Random(random_state).shuffle(fuzed_data)\n",
    "    \n",
    "    \n",
    "    # generate the dataloader\n",
    "    dl_train = torch_geometric.loader.DataLoader(fuzed_data, batch_size=(batch_size if aid!=686978 else batch_size*10))\n",
    "    dl_test = torch_geometric.loader.DataLoader([whole_data[idx] for idx in test_idx], batch_size=(batch_size if aid!=686978 else batch_size*10))\n",
    "    \n",
    "    # =================================================\n",
    "    # Model setup\n",
    "    # =================================================\n",
    "    # GNN model\n",
    "    model = GIN_nn.GIN_basic(1, drop_ratio=0.5)\n",
    "    # loss\n",
    "    loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([(len(train_idx) + len(sd_data))/(labels_hard[train_idx].sum() + torch.concatenate([data.y for data in sd_data]).numpy().sum())]))\n",
    "    # device\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device)\n",
    "    loss = loss.to(device)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # =================================================\n",
    "    # Epoch iteration\n",
    "    # =================================================\n",
    "    # define loss saving space\n",
    "    loss_storage = []\n",
    "    \n",
    "    # define accuracy storage\n",
    "    accuracy_storage = []\n",
    "    \n",
    "    # epoch iterations\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        # do training step\n",
    "        loss_value = execution.training(model, dl_train, device, optimizer, loss, verbose=False)\n",
    "\n",
    "        # put loss into storage\n",
    "        loss_storage.append(loss_value)\n",
    "\n",
    "        # do testing step\n",
    "        y_pred_hard = execution.predict(model, dl_test, device, reduce_to_hard_label=True, verbose=False)\n",
    "\n",
    "        # calculate accuracy DataFrame\n",
    "        accuracy_storage.append(\n",
    "            # get accuracy class and from it the DataFrame\n",
    "            accuracy.calculate_accuracies_1d(\n",
    "                y_pred=y_pred_hard, \n",
    "                y_true=accuracy.helper_pyg_to_numpy_label(\n",
    "                    data_loader=dl_test\n",
    "                )\n",
    "            ).to_df(index=epoch)\n",
    "        )\n",
    "    \n",
    "    # transform accuracy storage to pandas df\n",
    "    accuracy_storage = pd.concat(accuracy_storage)\n",
    "\n",
    "    # add new column for loss\n",
    "    accuracy_storage['loss'] = loss_storage\n",
    "    \n",
    "    # =================================================\n",
    "    # Save data to file\n",
    "    # =================================================\n",
    "    # set file path\n",
    "    file_path = csv_path + \"student-acc_aid={}_epochs={}.csv\".format(aid, epochs)\n",
    "    \n",
    "    # write to file\n",
    "    accuracy_storage.to_csv(file_path, index=True, index_label=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a395b-f73f-4af0-971a-065d1d9e4356",
   "metadata": {},
   "source": [
    "## Generate the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35cc91-e52c-4e5b-a820-74af605f1184",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-05T22:46:16.165227Z",
     "end_time": "2023-05-05T22:46:25.625531Z"
    }
   },
   "outputs": [],
   "source": [
    "for aid in aid_list:\n",
    "    \n",
    "    # if experiment in forbidden experiments skip it\n",
    "    if aid in forbidden_aid:\n",
    "        continue\n",
    "    \n",
    "    # determine storage location of csv\n",
    "    file_path = csv_path + \"student-acc_aid={}_epochs={}.csv\".format(aid, epochs)\n",
    "    \n",
    "    # determine storage location of image\n",
    "    file_path_plot = graphs_path + \"StudentAccs_aid-{}_epochs-{}.png\".format(aid, epochs)\n",
    "    \n",
    "    # load the csv\n",
    "    loaded_csv = pd.read_csv(file_path, index_col=\"epoch\")\n",
    "    \n",
    "    # plotting\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(loaded_csv.roc_score, label=\"roc_score\")\n",
    "    ax1.plot(loaded_csv.precision, label=\"precision\")\n",
    "    ax1.plot(loaded_csv.recall, label=\"recall\")\n",
    "    ax2.plot(loaded_csv.loss, color=\"black\", label=\"loss\")\n",
    "    \n",
    "    ax1.set_xlabel(\"epoch\")\n",
    "    ax1.set_ylabel(\"accuracy score\")\n",
    "    ax2.set_ylabel(\"loss score\")\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    plt.title(\"Accuracy scores on student model test - aid={}\".format(aid))\n",
    "    plt.savefig(file_path_plot, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08424452-e204-4660-bf67-03f662dd0dfc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T22:46:25.625531Z",
     "end_time": "2023-05-05T22:46:25.671112Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T22:46:25.641666Z",
     "end_time": "2023-05-05T22:46:25.671112Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
