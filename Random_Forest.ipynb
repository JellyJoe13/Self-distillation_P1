{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72ed1f1-cf18-4233-a636-4834d6cea766",
   "metadata": {},
   "source": [
    "# Random Forest Self Destillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9def00-2a6a-46b3-9c0d-2066bcc47ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoPa21\\anaconda3\\envs\\praktikum\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44730b5a-ffce-4ed5-b987-4038cd7b689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b549b42a-b8ed-4cdd-8957-9f696d49a6d1",
   "metadata": {},
   "source": [
    "## Import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc16f41e-00a5-4902-9a69-364d064d2767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff0db6-dd7d-470f-a8fe-6a51848e94d9",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd69ab7-792b-45e1-bc0d-fccf5a25ea68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path to dataset\n",
    "PATH_DATA = \"data/\"\n",
    "PATH_MAIN_DATASET = PATH_DATA + \"df_assay_entries.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8f670db-8d2b-46f2-945c-36206d1b6256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load whole dataset\n",
    "# df = pd.read_csv(PATH_MAIN_DATASET)\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c6fca7-3503-4e84-9b5c-399620fbbcaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into experiments\n",
    "def experiment_split(\n",
    "    df: pd.DataFrame,\n",
    "    PATH_DATA: str\n",
    ") -> np.ndarray:\n",
    "\n",
    "    # check if folder is present and if not create it\n",
    "    assert os.path.exists(PATH_DATA)\n",
    "    PATH_EXPERIMENTS = PATH_DATA + \"experiment-wise/\"\n",
    "    if not os.path.exists(PATH_EXPERIMENTS):\n",
    "        os.makedirs(PATH_EXPERIMENTS)\n",
    "\n",
    "    # get unique aids\n",
    "    aid_unique = np.unique(df.aid.to_numpy())\n",
    "    \n",
    "    # save aids as a content table\n",
    "    np.save(PATH_EXPERIMENTS + \"ToC.npy\", aid_unique)\n",
    "\n",
    "    # iterate over aids and compute subset - save subset to file\n",
    "    for id in tqdm(aid_unique):\n",
    "        # create file name\n",
    "        file_name = PATH_EXPERIMENTS + str(id) + \".csv\"\n",
    "        \n",
    "        # check if the dataset to this has already been created\n",
    "        if os.path.isfile(file_name):\n",
    "            continue\n",
    "        \n",
    "        # get subset\n",
    "        subset = df[df.aid==id]\n",
    "        # save subset to folder\n",
    "        subset.to_csv(\n",
    "            path_or_buf = file_name,\n",
    "            index = False\n",
    "        )\n",
    "    \n",
    "    # return experiment ids\n",
    "    return aid_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4b3568-fdf9-401c-92d7-f2aa38f56792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load and split into experiments\n",
    "def experiment_loadsplit(\n",
    "    PATH_DATA: str,\n",
    "    PATH_MAIN_DATASET: str = PATH_DATA + \"df_assay_entries.csv\"\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    # load the dataset into memory\n",
    "    df = pd.read_csv(PATH_MAIN_DATASET)\n",
    "\n",
    "    # execute normal split\n",
    "    return experiment_split(df, PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2447f904-d2d1-4cd0-834c-4b942a79b110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2481/2481 [00:00<00:00, 7865.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    411,     519,     523, ..., 1347425, 1479145, 1479148],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_loadsplit(PATH_DATA, PATH_MAIN_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762ef76-2424-48fd-905a-10440536e5db",
   "metadata": {},
   "source": [
    "## Individual Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392dbe2-fa6d-48a5-9026-63af042b3919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
